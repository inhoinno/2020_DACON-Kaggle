{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 불러오기\n",
    "train = pd.read_csv('open/train_processed_500.csv', encoding = 'utf-8')\n",
    "train_origin = pd.read_csv('open/train.csv', encoding = 'utf-8')\n",
    "test = pd.read_csv('open/test_x.csv', encoding = 'utf-8')\n",
    "sample_submission = pd.read_csv('open/sample_submission.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨: SSD\n",
      " 볼륨 일련 번호: BCA4-98AF\n",
      "\n",
      " C:\\Users\\inhoinno\\DACON\\2020_DACON-Kaggle\\소설저자AI 디렉터리\n",
      "\n",
      "2020-12-04  오전 01:08    <DIR>          .\n",
      "2020-12-04  오전 01:08    <DIR>          ..\n",
      "2020-12-04  오전 12:40    <DIR>          .ipynb_checkpoints\n",
      "2020-11-26  오후 10:42            75,612 15_lstm_glove_inhoinho_v0_1.ipynb\n",
      "2020-12-02  오후 06:12            76,044 15_lstm_glove_inhoinho_v0_2_ipynb의_사본.ipynb\n",
      "2020-11-26  오후 08:29            38,607 15-lstm-glove-inho.ipynb\n",
      "2020-11-24  오전 10:49            33,874 Augmentation.ipynb\n",
      "2020-12-01  오후 04:01    <DIR>          build\n",
      "2020-12-02  오후 09:19           318,220 CNN_CV_shared.ipynb\n",
      "2020-12-03  오후 10:14            98,597 CNN_CV_shared-Refactoring.ipynb\n",
      "2020-11-24  오전 11:15    <DIR>          dataset\n",
      "2020-11-26  오후 08:29    <DIR>          dku-kaggle-class\n",
      "2020-12-04  오전 12:45           110,604 DNN_CV_shared-Refactoring.ipynb\n",
      "2020-12-01  오후 04:01    <DIR>          drive\n",
      "2020-11-05  오후 05:31    <DIR>          ensemble\n",
      "2020-11-26  오후 11:01           874,542 Logistic_Linear_Regression.ipynb\n",
      "2020-10-09  오후 05:05         1,327,724 Logistic_regression.ipynb\n",
      "2020-12-04  오전 12:08           111,189 lstm_glove_hypopt.ipynb\n",
      "2020-11-30  오전 12:35           862,429 NaiveBaise_SVM.ipynb\n",
      "2020-10-29  오후 06:12         3,959,848 NPL_base_5layer.h5\n",
      "2020-11-12  오전 11:23            35,818 NPL_BaseLine.ipynb\n",
      "2020-11-26  오후 07:38           944,315 NPL_BaseLine-CV.ipynb\n",
      "2020-11-26  오후 07:31            54,108 NPL_BaseLine-CV-Copy1.ipynb\n",
      "2020-11-05  오전 12:07           934,892 NPL_BaseLine-LSTM.ipynb\n",
      "2020-11-12  오전 11:23           942,567 NPL_BaseLine-ONE-HOT.ipynb\n",
      "2020-11-20  오후 05:49           115,342 NPL_Base-Tfidf-CV.ipynb\n",
      "2020-11-20  오후 05:49           115,342 NPL_Base-Tfidf-CV-Copy1.ipynb\n",
      "2020-11-12  오전 11:23           927,110 NPL_LSTM_CV-Copy1.ipynb\n",
      "2020-11-12  오전 11:28           941,359 NPL_LSTM-CV-Embedding.ipynb\n",
      "2020-11-17  오후 01:59            45,713 NPL_LSTM-CV-Embedding-Glove.ipynb\n",
      "2020-11-12  오후 10:35            39,893 NPL_RNN_Embedding.ipynb\n",
      "2020-11-12  오전 11:23           952,895 NPL_RNN-CV.ipynb\n",
      "2020-11-23  오후 05:46            44,955 NPL_RNN-CV-Copy2.ipynb\n",
      "2020-11-20  오후 05:29    <DIR>          open\n",
      "2020-10-29  오후 02:41         9,263,779 open.zip\n",
      "2020-12-02  오후 05:01           104,753 RandomForest_LGBM.ipynb\n",
      "2020-11-26  오후 06:57         1,906,926 RNN_Embedding(TODO).ipynb\n",
      "2020-12-04  오전 12:40         1,902,837 RNN_Embedding(TODO)-Copy1.ipynb\n",
      "2020-12-04  오전 01:08            64,577 RNN_Embedding(TODO)-Copy2.ipynb\n",
      "2020-10-09  오후 05:03         1,529,784 Stacking_LGBM_Metamodel.ipynb\n",
      "2020-10-09  오후 03:27           805,203 Stacking_xgboost_0.ipynb\n",
      "              32개 파일          29,559,458 바이트\n",
      "               9개 디렉터리  31,645,503,488 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "ls \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>183468.000000</td>\n",
       "      <td>183468.000000</td>\n",
       "      <td>183468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91733.500000</td>\n",
       "      <td>2.049088</td>\n",
       "      <td>162.545567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52962.793931</td>\n",
       "      <td>1.285455</td>\n",
       "      <td>178.318420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45866.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91733.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137600.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>183467.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2454.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         author         length\n",
       "count  183468.000000  183468.000000  183468.000000\n",
       "mean    91733.500000       2.049088     162.545567\n",
       "std     52962.793931       1.285455     178.318420\n",
       "min         0.000000       0.000000       4.000000\n",
       "25%     45866.750000       1.000000      63.000000\n",
       "50%     91733.500000       2.000000     112.000000\n",
       "75%    137600.250000       3.000000     188.000000\n",
       "max    183467.000000       4.000000    2454.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['length'] = train['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>Tell me what it is.</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>I said Not at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>I dare say she had.</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>I am to be neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>And where was it</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182119</th>\n",
       "      <td>182119</td>\n",
       "      <td>Yes said he</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182148</th>\n",
       "      <td>182148</td>\n",
       "      <td>He thus continued</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182210</th>\n",
       "      <td>182210</td>\n",
       "      <td>Wait up for me</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182241</th>\n",
       "      <td>182241</td>\n",
       "      <td>How do you do Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182425</th>\n",
       "      <td>182425</td>\n",
       "      <td>odin did not stir</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                 text  author  length\n",
       "107        107  Tell me what it is.       0      19\n",
       "219        219   I said Not at all.       0      18\n",
       "418        418  I dare say she had.       1      19\n",
       "829        829   I am to be neutral       2      18\n",
       "873        873     And where was it       2      17\n",
       "...        ...                  ...     ...     ...\n",
       "182119  182119         Yes said he        3      13\n",
       "182148  182148    He thus continued       1      18\n",
       "182210  182210       Wait up for me       1      15\n",
       "182241  182241    How do you do Mr        1      18\n",
       "182425  182425    odin did not stir       3      18\n",
       "\n",
       "[2455 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['length'] < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#부호를 제거해주는 함수\n",
    "\n",
    "def alpha_num(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
    "\n",
    "train['text']=train['text'].apply(alpha_num)\n",
    "\n",
    "\n",
    "#1. 불용어 제거 remove_stopwords\n",
    "# 불용어 제거해주는 함수\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "# 불용어\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"odin\",\n",
    "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
    "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
    "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
    "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
    "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
    "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 적용\n",
    "train['text'] = train['text'].str.lower()\n",
    "test['text'] = test['text'].str.lower()\n",
    "train['text'] = train['text'].apply(alpha_num).apply(remove_stopwords)\n",
    "test['text'] = test['text'].apply(alpha_num).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>tell</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>said not</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>dare say</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182119</th>\n",
       "      <td>182119</td>\n",
       "      <td>yes said</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182148</th>\n",
       "      <td>182148</td>\n",
       "      <td>thus continued</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182210</th>\n",
       "      <td>182210</td>\n",
       "      <td>wait</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182241</th>\n",
       "      <td>182241</td>\n",
       "      <td>mr</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182425</th>\n",
       "      <td>182425</td>\n",
       "      <td>not stir</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index            text  author  length\n",
       "107        107            tell       0      19\n",
       "219        219        said not       0      18\n",
       "418        418        dare say       1      19\n",
       "829        829         neutral       2      18\n",
       "873        873                       2      17\n",
       "...        ...             ...     ...     ...\n",
       "182119  182119        yes said       3      13\n",
       "182148  182148  thus continued       1      18\n",
       "182210  182210            wait       1      15\n",
       "182241  182241              mr       1      18\n",
       "182425  182425        not stir       3      18\n",
       "\n",
       "[2455 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['length'] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>181013.000000</td>\n",
       "      <td>181013.000000</td>\n",
       "      <td>181013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91514.586997</td>\n",
       "      <td>2.049146</td>\n",
       "      <td>164.537862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>53025.418222</td>\n",
       "      <td>1.286300</td>\n",
       "      <td>178.695183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45490.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91441.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137458.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>183467.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2454.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         author         length\n",
       "count  181013.000000  181013.000000  181013.000000\n",
       "mean    91514.586997       2.049146     164.537862\n",
       "std     53025.418222       1.286300     178.695183\n",
       "min         0.000000       0.000000      20.000000\n",
       "25%     45490.000000       1.000000      65.000000\n",
       "50%     91441.000000       2.000000     113.000000\n",
       "75%    137458.000000       3.000000     189.000000\n",
       "max    183467.000000       4.000000    2454.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_under_20 = train[train['length'] < 20].index\n",
    "train = train.drop(idx_under_20)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>engaged one day walked perusing janes last let...</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>captain porch keeping carefully way treacherou...</td>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mercy gentlemen flung hands dont write anyway ...</td>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183463</th>\n",
       "      <td>183463</td>\n",
       "      <td>urging opinion sir odins proof extremity case ...</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183464</th>\n",
       "      <td>183464</td>\n",
       "      <td>many tears unwritten contract drawn us first n...</td>\n",
       "      <td>3</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183465</th>\n",
       "      <td>183465</td>\n",
       "      <td>express consciousness no enemy punish pain con...</td>\n",
       "      <td>3</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183466</th>\n",
       "      <td>183466</td>\n",
       "      <td>course knows no sort good moans knows better a...</td>\n",
       "      <td>3</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183467</th>\n",
       "      <td>183467</td>\n",
       "      <td>grocers oh grocers nearly closed perhaps two s...</td>\n",
       "      <td>0</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181013 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                               text  author  \\\n",
       "0            0  almost choking much much wanted say strange ex...       3   \n",
       "1            1                               sister asked suppose       2   \n",
       "2            2  engaged one day walked perusing janes last let...       1   \n",
       "3            3  captain porch keeping carefully way treacherou...       4   \n",
       "4            4  mercy gentlemen flung hands dont write anyway ...       3   \n",
       "...        ...                                                ...     ...   \n",
       "183463  183463  urging opinion sir odins proof extremity case ...       1   \n",
       "183464  183464  many tears unwritten contract drawn us first n...       3   \n",
       "183465  183465  express consciousness no enemy punish pain con...       3   \n",
       "183466  183466  course knows no sort good moans knows better a...       3   \n",
       "183467  183467  grocers oh grocers nearly closed perhaps two s...       0   \n",
       "\n",
       "        length  \n",
       "0          235  \n",
       "1           34  \n",
       "2          312  \n",
       "3          305  \n",
       "4          215  \n",
       "...        ...  \n",
       "183463     571  \n",
       "183464     536  \n",
       "183465     525  \n",
       "183466     515  \n",
       "183467     679  \n",
       "\n",
       "[181013 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates(['text'])\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>almost choking much much wanted say strange ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sister asked suppose</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>engaged one day walked perusing janes last let...</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>captain porch keeping carefully way treacherou...</td>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>mercy gentlemen flung hands dont write anyway ...</td>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94973</th>\n",
       "      <td>97289</td>\n",
       "      <td>97289</td>\n",
       "      <td>diningroom soon joined busily engaged separate...</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94974</th>\n",
       "      <td>97290</td>\n",
       "      <td>97290</td>\n",
       "      <td>one came books toilette</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94975</th>\n",
       "      <td>97291</td>\n",
       "      <td>97291</td>\n",
       "      <td>faces however tolerably calm no change visible...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94976</th>\n",
       "      <td>97292</td>\n",
       "      <td>97292</td>\n",
       "      <td>still ticking hall</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94977</th>\n",
       "      <td>139706</td>\n",
       "      <td>139706</td>\n",
       "      <td>mistress enough whisper countenance grave refl...</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94978 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0   index                                               text  \\\n",
       "0            0       0  almost choking much much wanted say strange ex...   \n",
       "1            1       1                               sister asked suppose   \n",
       "2            2       2  engaged one day walked perusing janes last let...   \n",
       "3            3       3  captain porch keeping carefully way treacherou...   \n",
       "4            4       4  mercy gentlemen flung hands dont write anyway ...   \n",
       "...        ...     ...                                                ...   \n",
       "94973    97289   97289  diningroom soon joined busily engaged separate...   \n",
       "94974    97290   97290                            one came books toilette   \n",
       "94975    97291   97291  faces however tolerably calm no change visible...   \n",
       "94976    97292   97292                                 still ticking hall   \n",
       "94977   139706  139706  mistress enough whisper countenance grave refl...   \n",
       "\n",
       "       author  length  \n",
       "0           3     235  \n",
       "1           2      34  \n",
       "2           1     312  \n",
       "3           4     305  \n",
       "4           3     215  \n",
       "...       ...     ...  \n",
       "94973       1     150  \n",
       "94974       1      56  \n",
       "94975       1     252  \n",
       "94976       2      29  \n",
       "94977       1     142  \n",
       "\n",
       "[94978 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot, 해싱, Bow(< 이건 RF와 LGBM에서 사용하자)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[파이썬 라이브러리를 활용한 머신러닝] 7.3장 : 텍스트 데이터를 BOW로 표현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500 #100개 이후 단어는 버려\n",
    "max_words = 50000 #데이터셋에서 가장 빈도 높은 1만개의 단어만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "sequences = tokenizer.texts_to_sequences(train['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47151개의 고유한 토큰 확인\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('%s개의 고유한 토큰 확인'%len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 텐서 크기 (94978, 500)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen= maxlen)\n",
    "print('데이터 텐서 크기',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. 벡터화 (임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = './dataset/glove.6B/'\n",
    "embeddings_index={}\n",
    "f = open(os.path.join(glove_dir,'glove.6B.100d.txt'), encoding =\"utf8\")\n",
    "\n",
    "for line in f : \n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word]=coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400001개의 단어 벡터 확인 \n"
     ]
    }
   ],
   "source": [
    "print('%s개의 단어 벡터 확인 '%len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove 단어 임베딩 행렬 준비하기\n",
    "#임베딩 전처리\n",
    "#임베딩 행렬 준비하기\n",
    "embedding_dim=100\n",
    "#global embedding_matrix\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i< max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None :\n",
    "            embedding_matrix[i] = embedding_vector# 임베딩 인덱스에 없는 단어는 모두 0이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense,GlobalAveragePooling2D\n",
    "from keras.layers import LSTM, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.19103999,  0.17601   ,  0.36919999, ..., -0.59680003,\n",
       "         0.080843  ,  0.27866   ],\n",
       "       [-0.13128   , -0.45199999,  0.043399  , ..., -0.30526   ,\n",
       "        -0.045495  ,  0.56509   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 5\n",
    "from keras.metrics import *\n",
    "from keras.layers import *\n",
    "def get_base_model():\n",
    "    #model = DNNClassifier(**kargs)\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(max_words, embedding_dim, weights = [embedding_matrix], trainable =False ,input_length=maxlen),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1024, activation='relu', ),\n",
    "        Dropout(0.15),\n",
    "        Dense(256, activation = 'relu'),\n",
    "        Dropout(0.15),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(5, activation='softmax'),\n",
    "        Dense(n_class, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=.01),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = get_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####         500\n",
      "           Embedding   emb | -------------------   5000000    92.9%\n",
      "                       #####    500  100\n",
      "GlobalAveragePooling1D   Y^avg -------------------         0     0.0%\n",
      "                       #####         100\n",
      "               Dense   XXXXX -------------------    103424     1.9%\n",
      "                relu   #####        1024\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####        1024\n",
      "               Dense   XXXXX -------------------    262400     4.9%\n",
      "                relu   #####         256\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####         256\n",
      "               Dense   XXXXX -------------------     16448     0.3%\n",
      "                relu   #####          64\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####          64\n",
      "               Dense   XXXXX -------------------      1040     0.0%\n",
      "                relu   #####          16\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####          16\n",
      "               Dense   XXXXX -------------------        85     0.0%\n",
      "             softmax   #####           5\n",
      "               Dense   XXXXX -------------------        30     0.0%\n",
      "             softmax   #####           5\n"
     ]
    }
   ],
   "source": [
    "from keras_sequential_ascii import keras2ascii\n",
    "\n",
    "keras2ascii(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.compile(loss='sparse_categorical_crossentropy',\\n              optimizer='adam',\\n              metrics=['accuracy'])\\nprint(model.summary())\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([x for x in train['text']])\n",
    "X_test = np.array([x for x in test['text']])\n",
    "y_train = np.array([x for x in train['author']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_type='post'\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=maxlen)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_epochs = 20\\nhistory = model.fit(train_padded, y_train, \\n                    epochs=num_epochs, verbose=2, \\n                    validation_split=0.2)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_epochs = 20\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=2, \n",
    "                    validation_split=0.2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 777\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.5737 - accuracy: 0.2985 - val_loss: 1.5725 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.5729 - accuracy: 0.3002 - val_loss: 1.5718 - val_accuracy: 0.3003\n",
      "Epoch 3/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.5730 - accuracy: 0.3003 - val_loss: 1.5720 - val_accuracy: 0.3003\n",
      "training model for CV #2\n",
      "Epoch 1/20\n",
      "1188/1188 [==============================] - 9s 7ms/step - loss: 1.5738 - accuracy: 0.2989 - val_loss: 1.5734 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "1188/1188 [==============================] - 8s 7ms/step - loss: 1.5728 - accuracy: 0.3003 - val_loss: 1.5727 - val_accuracy: 0.3003\n",
      "Epoch 3/20\n",
      "1188/1188 [==============================] - 8s 7ms/step - loss: 1.5728 - accuracy: 0.3003 - val_loss: 1.5729 - val_accuracy: 0.3003\n",
      "training model for CV #3\n",
      "Epoch 1/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.5741 - accuracy: 0.2990 - val_loss: 1.5740 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5736 - accuracy: 0.3000 - val_loss: 1.5747 - val_accuracy: 0.3003\n",
      "Epoch 3/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5732 - accuracy: 0.3003 - val_loss: 1.5717 - val_accuracy: 0.3003\n",
      "Epoch 4/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5730 - accuracy: 0.3003 - val_loss: 1.5730 - val_accuracy: 0.3003\n",
      "Epoch 5/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5728 - accuracy: 0.3003 - val_loss: 1.5721 - val_accuracy: 0.3003\n",
      "training model for CV #4\n",
      "Epoch 1/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5175 - accuracy: 0.3401 - val_loss: 1.4511 - val_accuracy: 0.3935\n",
      "Epoch 2/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4564 - accuracy: 0.3910 - val_loss: 1.4105 - val_accuracy: 0.4114\n",
      "Epoch 3/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.4290 - accuracy: 0.4036 - val_loss: 1.3958 - val_accuracy: 0.4193\n",
      "Epoch 4/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.4179 - accuracy: 0.4050 - val_loss: 1.3991 - val_accuracy: 0.4056\n",
      "Epoch 5/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4115 - accuracy: 0.4055 - val_loss: 1.3810 - val_accuracy: 0.4372\n",
      "Epoch 6/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4119 - accuracy: 0.4091 - val_loss: 1.3779 - val_accuracy: 0.4267\n",
      "Epoch 7/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4034 - accuracy: 0.4143 - val_loss: 1.3689 - val_accuracy: 0.4316\n",
      "Epoch 8/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4018 - accuracy: 0.4152 - val_loss: 1.3733 - val_accuracy: 0.4400\n",
      "Epoch 9/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4000 - accuracy: 0.4174 - val_loss: 1.3650 - val_accuracy: 0.4315\n",
      "Epoch 10/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4003 - accuracy: 0.4138 - val_loss: 1.3917 - val_accuracy: 0.4162\n",
      "Epoch 11/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4017 - accuracy: 0.4133 - val_loss: 1.3718 - val_accuracy: 0.4307\n",
      "training model for CV #5\n",
      "Epoch 1/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.5077 - accuracy: 0.3371 - val_loss: 1.4658 - val_accuracy: 0.3735\n",
      "Epoch 2/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4602 - accuracy: 0.3804 - val_loss: 1.4100 - val_accuracy: 0.4179\n",
      "Epoch 3/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4336 - accuracy: 0.3983 - val_loss: 1.4330 - val_accuracy: 0.3993\n",
      "Epoch 4/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4164 - accuracy: 0.4050 - val_loss: 1.3809 - val_accuracy: 0.4203\n",
      "Epoch 5/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4075 - accuracy: 0.4096 - val_loss: 1.3820 - val_accuracy: 0.4309\n",
      "Epoch 6/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4028 - accuracy: 0.4157 - val_loss: 1.3767 - val_accuracy: 0.4351\n",
      "Epoch 7/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.4009 - accuracy: 0.4182 - val_loss: 1.3694 - val_accuracy: 0.4346\n",
      "Epoch 8/20\n",
      "1188/1188 [==============================] - 9s 8ms/step - loss: 1.3980 - accuracy: 0.4194 - val_loss: 1.3757 - val_accuracy: 0.4297\n",
      "Epoch 9/20\n",
      "1188/1188 [==============================] - 10s 8ms/step - loss: 1.3924 - accuracy: 0.4234 - val_loss: 1.4131 - val_accuracy: 0.4099\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical \n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "trn = train_padded\n",
    "tst = test_padded\n",
    "y = y_train\n",
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn,y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    \n",
    "    clf = get_base_model()\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=2,\n",
    "                       verbose=0, mode='min', baseline=None, restore_best_weights=True)\n",
    "    \n",
    "\n",
    "\n",
    "    clf.fit(trn[i_trn], \n",
    "            y[i_trn],\n",
    "            validation_data=(trn[i_val],y[i_val]),\n",
    "            epochs=20,\n",
    "            batch_size = 64,\n",
    "            callbacks=[es],\n",
    "           verbose = 1)\n",
    "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
    "    p_tst += clf.predict_proba(tst) / n_fold\n",
    "    del(clf)\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc  = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, acc , 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label= 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train, y_train,cv=5)\n",
    "print(\"cv test score : {:/2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train_origin, y_train_origin,cv=5)\n",
    "print(\"cv test score : {:/2f}\".format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
