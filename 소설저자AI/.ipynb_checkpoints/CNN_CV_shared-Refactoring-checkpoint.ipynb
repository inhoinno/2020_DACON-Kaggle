{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pathlib import Path\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./open')\n",
    "feature_dir = Path('./build/feature')\n",
    "val_dir = Path('./ensemble/build/val')\n",
    "tst_dir = Path('./ensemble/build/tst')\n",
    "sub_dir = Path('./open/sub')\n",
    "dirs = [feature_dir, val_dir, tst_dir, sub_dir]\n",
    "for d in dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "trn_file = data_dir / 'train_processed_500.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "glove_file = './dataset/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = 'cnn'\n",
    "feature_name = 'glove'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(glove_file, encoding = 'UTF8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      He was almost choking. There was so much, so m...       3\n",
       "1                 “Your sister asked for it, I suppose?”       2\n",
       "2       She was engaged one day as she walked, in per...       1\n",
       "3      The captain was in the porch, keeping himself ...       4\n",
       "4      “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(trn_file, index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "index                                                   \n",
       "0      “Not at all. I think she is one of the most ch...\n",
       "1      \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      As the lady had stated her intention of scream...\n",
       "3      “And then suddenly in the silence I heard a so...\n",
       "4      His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(tst_file, index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_num(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"odin\",\n",
    "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
    "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
    "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
    "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
    "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
    "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_stopwords)\n",
    "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['length'] = train['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49420.000000</td>\n",
       "      <td>49420.000000</td>\n",
       "      <td>49420.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27442.838062</td>\n",
       "      <td>1.940004</td>\n",
       "      <td>143.06467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15852.437381</td>\n",
       "      <td>1.403680</td>\n",
       "      <td>165.90232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13715.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27403.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41203.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>169.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54878.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1387.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index        author       length\n",
       "count  49420.000000  49420.000000  49420.00000\n",
       "mean   27442.838062      1.940004    143.06467\n",
       "std    15852.437381      1.403680    165.90232\n",
       "min        0.000000      0.000000     20.00000\n",
       "25%    13715.750000      1.000000     42.00000\n",
       "50%    27403.500000      2.000000     75.00000\n",
       "75%    41203.250000      3.000000    169.00000\n",
       "max    54878.000000      4.000000   1387.00000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_under_20 = train[train['length'] < 20].index\n",
    "train = train.drop(idx_under_20)\n",
    "train = train.reset_index()\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c229abec10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 274,
       "width": 388
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby(train.author).size().reset_index(name=\"counts\").plot.bar(x='author',title=\"Samples per each class (Training set)\",color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49420,) (19617,) (49420,)\n"
     ]
    }
   ],
   "source": [
    "trn = train['text'].values\n",
    "tst = test['text'].values\n",
    "y = train['author'].values\n",
    "print(trn.shape, tst.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 200\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(train.text, train.author, test_size=0.2, random_state=3,stratify= train.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=500000)\n",
    "tokenizer.fit_on_texts(trn)\n",
    "sequences_train = tokenizer.texts_to_sequences(trn)\n",
    "sequences_test = tokenizer.texts_to_sequences(tst)\n",
    "sequences_validation = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (49420, 500)\n",
      "Validation set shape: (9884, 500)\n",
      "Test set shape: (19617, 500)\n"
     ]
    }
   ],
   "source": [
    "max_length = 500\n",
    "from keras.preprocessing import sequence\n",
    "x_train=sequence.pad_sequences(sequences_train,maxlen=max_length)\n",
    "x_validation=sequence.pad_sequences(sequences_validation,maxlen=max_length)\n",
    "tst=sequence.pad_sequences(sequences_test,maxlen=max_length)\n",
    "\n",
    "print(f\"Train set shape: {x_train.shape}\\nValidation set shape: {x_validation.shape}\\nTest set shape: {tst.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y_train_categorical=encoder.fit_transform(y_trn.values.reshape(-1, 1))\n",
    "y_validation_categorical=encoder.transform(train['author'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set labels: 39536\n",
      "Validation set labels: 49420\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set labels: {y_train_categorical.__len__()}\\nValidation set labels: {y_validation_categorical.__len__()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Glove 임베딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = './dataset/glove.6B/glove.6B.100d.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(glove_file, encoding = 'UTF8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "max_words = tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i< max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None :\n",
    "            embedding_matrix[i] = embedding_vector# 임베딩 인덱스에 없는 단어는 모두 0이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> CNN 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(batch_size, time_steps, trn, y):\n",
    "    \"\"\"\n",
    "    function that returns data to be fed into objective function and model is trained on it subsequently.\n",
    "    \"\"\"\n",
    "    BATCH_SIZE = batch_size\n",
    "    TIME_STEPS = time_steps\n",
    "    X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=.2, random_state=seed)\n",
    "    return  X_trn, X_val, y_trn, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    #'batch_size': hp.choice('bs', [30,40,50,60,70]),\n",
    "    #'time_steps': hp.choice('ts', [30,50,60,80,90]),\n",
    "    'embedding_dim' : 100,\n",
    "    'embedding_matrix' : embedding_matrix,\n",
    "    'cnn1_nodes': hp.choice('units_lsmt1', [32,64,80]),\n",
    "    'cnn1_dropouts': hp.uniform('dos_lstm1',0,0.5),\n",
    "    \n",
    "    'dense_layers': hp.choice('num_layers_dense',[\n",
    "        {\n",
    "            'layers':'one'\n",
    "        },\n",
    "        {\n",
    "            'layers':'two',\n",
    "            'dense2_nodes': hp.choice('units_dense', [10,16,32,40])\n",
    "        }\n",
    "        ]),\n",
    "    \"lr\": hp.loguniform('lr',np.log(0.01), np.log(0.1)),\n",
    "    \"epochs\": 30,\n",
    "    \"optimizer\": \"Adam\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "from keras import Sequential,optimizers\n",
    "from keras_sequential_ascii import keras2ascii\n",
    "\n",
    "class CNNtext(Sequential):\n",
    "    \"\"\"\n",
    "    This class extends  keras.sequencial in order to build our \n",
    "    model according to the designed architecture\n",
    "    \"\"\"\n",
    "    #params for the convolutional layers\n",
    "    __num_filters = 64\n",
    "    __weight_decay = 1e-4\n",
    "    #optimizers\n",
    "    __adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    def __init__(self,max_length,number_of_classes,embedding_matrix=None,vocab_size=None,tokenizer=None):\n",
    "        #creating the model heritance from Keras.sequencial\n",
    "        super().__init__()\n",
    "        #params for the embedding layer\n",
    "        self.__embedding_dim=100 if embedding_matrix is None else embedding_matrix.shape[1]\n",
    "        #self.__vocab_size=vocab_size if tokenizer is None else tokenizer.word_index.__len__()+1\n",
    "        self.__vocab_size=vocab_size if tokenizer is None else max(tokenizer.index_word.keys())+1\n",
    "        try:\n",
    "            self.__max_length=max_length\n",
    "            self.__number_of_classes=number_of_classes \n",
    "        except NameError as error:\n",
    "            print(\"Error \",error,\" must be defined.\")\n",
    "            \n",
    "        #defining layers\n",
    "        #This layer will learn an embedding the vocab_size is the vocabulary learn from our tokenizer\n",
    "        #the embedding dimension is defined by our selfs in this case we choose a dimension of 100\n",
    "        #the input length is the maximum length of the documents we will use\n",
    "        if embedding_matrix is None:\n",
    "            self.add(Embedding(self.__vocab_size,\n",
    "                               self.__embedding_dim,\n",
    "                               input_length=self.__max_length,trainable=True))\n",
    "        else:\n",
    "            self.add(Embedding(embedding_matrix.shape[0],\n",
    "                               embedding_matrix.shape[1],\n",
    "                               weights=[embedding_matrix],\n",
    "                               input_length=self.__max_length,\n",
    "                               trainable=False))\n",
    "        #then we apply a 1D conv layer that should apply filters to the sequence and generate features maps.\n",
    "        self.add(Conv1D(self.__num_filters, 7, activation='relu', padding='same'))\n",
    "        #then we will get the most important features using a max pooling layer\n",
    "        self.add(MaxPooling1D(2))\n",
    "        #afterwards we apply a conv 1D layer to learn new features form the previous results\n",
    "        self.add(Conv1D(self.__num_filters, 7, activation='relu', padding='same'))\n",
    "        #we select again the most important features\n",
    "        self.add(GlobalMaxPooling1D())\n",
    "        #then we apply dropout to improve the generalization\n",
    "        self.add(Dropout(0.5))\n",
    "        #then we will pass the results into a dense layer that will also learn some internal representation and we also use the l2 regularization\n",
    "        self.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(self.__weight_decay)))\n",
    "        #for the final layer we will use softmax to obtain the probabilities of each class.\n",
    "        self.add(Dense(self.__number_of_classes, activation='softmax'))  \n",
    "        #to compute the loss function we use binary_crossentropy\n",
    "        #which is widely used for multi-classification problems\n",
    "        #we also use the adam optimazer to learn the parameters(weights)\n",
    "        #and minimize the loss function.\n",
    "        # 몰랐는데 binary_crossentropy가 multi-classification 에 좋다고 하는군요.\n",
    "        # binary_crossentropy는 반드시 binary-classification에만 써야 하는건줄 알았는데...\n",
    "        self.compile(loss='categorical_crossentropy', optimizer=self.__adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training params\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_BOW=CNNtext(max_length,\n",
    "              encoder.classes_.__len__(),\n",
    "              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####         500\n",
      "           Embedding   emb | -------------------   4705700    98.4%\n",
      "                       #####    500  100\n",
      "              Conv1D    \\|/  -------------------     44864     0.9%\n",
      "                relu   #####    500   64\n",
      "        MaxPooling1D   Y max -------------------         0     0.0%\n",
      "                       #####    250   64\n",
      "              Conv1D    \\|/  -------------------     28736     0.6%\n",
      "                relu   #####    250   64\n",
      "  GlobalMaxPooling1D   Y^max -------------------         0     0.0%\n",
      "                       #####          64\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####          64\n",
      "               Dense   XXXXX -------------------      2080     0.0%\n",
      "                relu   #####          32\n",
      "               Dense   XXXXX -------------------       165     0.0%\n",
      "             softmax   #####           5\n"
     ]
    }
   ],
   "source": [
    "keras2ascii(CNN_BOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49420, 500), (39536, 5), (9884, 500), (49420, 5))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train_categorical.shape, x_validation.shape, y_validation_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49420, 500), (49420,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19617, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/15\n",
      "1236/1236 [==============================] - 98s 79ms/step - loss: 1.0995 - accuracy: 0.5537 - val_loss: 0.7861 - val_accuracy: 0.6999\n",
      "Epoch 2/15\n",
      "1236/1236 [==============================] - 94s 76ms/step - loss: 0.6179 - accuracy: 0.7785 - val_loss: 0.7098 - val_accuracy: 0.7432\n",
      "Epoch 3/15\n",
      "1236/1236 [==============================] - 92s 75ms/step - loss: 0.4031 - accuracy: 0.8608 - val_loss: 0.7597 - val_accuracy: 0.7479\n",
      "Epoch 4/15\n",
      "1236/1236 [==============================] - 97s 78ms/step - loss: 0.2778 - accuracy: 0.9048 - val_loss: 0.9323 - val_accuracy: 0.7442\n",
      "Epoch 5/15\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9351Restoring model weights from the end of the best epoch.\n",
      "1236/1236 [==============================] - 96s 78ms/step - loss: 0.1929 - accuracy: 0.9351 - val_loss: 1.0601 - val_accuracy: 0.7265\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/15\n",
      "1236/1236 [==============================] - 99s 80ms/step - loss: 1.0545 - accuracy: 0.5752 - val_loss: 0.7713 - val_accuracy: 0.7084\n",
      "Epoch 2/15\n",
      "1236/1236 [==============================] - 96s 77ms/step - loss: 0.5840 - accuracy: 0.7922 - val_loss: 0.6942 - val_accuracy: 0.7468\n",
      "Epoch 3/15\n",
      "1236/1236 [==============================] - 96s 78ms/step - loss: 0.3735 - accuracy: 0.8713 - val_loss: 0.7557 - val_accuracy: 0.7518\n",
      "Epoch 4/15\n",
      "1236/1236 [==============================] - 94s 76ms/step - loss: 0.2519 - accuracy: 0.9148 - val_loss: 0.8262 - val_accuracy: 0.7500\n",
      "Epoch 5/15\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9441Restoring model weights from the end of the best epoch.\n",
      "1236/1236 [==============================] - 95s 77ms/step - loss: 0.1707 - accuracy: 0.9441 - val_loss: 0.9935 - val_accuracy: 0.7437\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/15\n",
      "1236/1236 [==============================] - 96s 78ms/step - loss: 1.1033 - accuracy: 0.5581 - val_loss: 0.8062 - val_accuracy: 0.6969\n",
      "Epoch 2/15\n",
      "1236/1236 [==============================] - 95s 77ms/step - loss: 0.6203 - accuracy: 0.7781 - val_loss: 0.7396 - val_accuracy: 0.7323\n",
      "Epoch 3/15\n",
      "1236/1236 [==============================] - 97s 79ms/step - loss: 0.3979 - accuracy: 0.8648 - val_loss: 0.7885 - val_accuracy: 0.7351\n",
      "Epoch 4/15\n",
      "1236/1236 [==============================] - 97s 78ms/step - loss: 0.2610 - accuracy: 0.9117 - val_loss: 0.9643 - val_accuracy: 0.7276\n",
      "Epoch 5/15\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9416Restoring model weights from the end of the best epoch.\n",
      "1236/1236 [==============================] - 98s 79ms/step - loss: 0.1766 - accuracy: 0.9416 - val_loss: 1.0617 - val_accuracy: 0.7338\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/15\n",
      "1236/1236 [==============================] - 95s 77ms/step - loss: 1.0783 - accuracy: 0.5659 - val_loss: 0.8162 - val_accuracy: 0.6876\n",
      "Epoch 2/15\n",
      "1236/1236 [==============================] - 97s 78ms/step - loss: 0.6307 - accuracy: 0.7682 - val_loss: 0.7437 - val_accuracy: 0.7311\n",
      "Epoch 3/15\n",
      "1236/1236 [==============================] - 96s 78ms/step - loss: 0.4090 - accuracy: 0.8590 - val_loss: 0.7770 - val_accuracy: 0.7379\n",
      "Epoch 4/15\n",
      "1236/1236 [==============================] - 96s 77ms/step - loss: 0.2744 - accuracy: 0.9079 - val_loss: 0.9129 - val_accuracy: 0.7365\n",
      "Epoch 5/15\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9393Restoring model weights from the end of the best epoch.\n",
      "1236/1236 [==============================] - 95s 77ms/step - loss: 0.1832 - accuracy: 0.9393 - val_loss: 1.0593 - val_accuracy: 0.7309\n",
      "Epoch 00005: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/15\n",
      "1236/1236 [==============================] - 94s 76ms/step - loss: 1.1268 - accuracy: 0.5396 - val_loss: 0.8826 - val_accuracy: 0.6490\n",
      "Epoch 2/15\n",
      "1236/1236 [==============================] - 95s 77ms/step - loss: 0.7096 - accuracy: 0.7218 - val_loss: 0.7549 - val_accuracy: 0.7240\n",
      "Epoch 3/15\n",
      "1236/1236 [==============================] - 93s 75ms/step - loss: 0.4588 - accuracy: 0.8369 - val_loss: 0.7407 - val_accuracy: 0.7407\n",
      "Epoch 4/15\n",
      "1236/1236 [==============================] - 94s 76ms/step - loss: 0.3014 - accuracy: 0.8984 - val_loss: 0.8221 - val_accuracy: 0.7407\n",
      "Epoch 5/15\n",
      "1236/1236 [==============================] - 98s 80ms/step - loss: 0.2079 - accuracy: 0.9300 - val_loss: 1.0000 - val_accuracy: 0.7404\n",
      "Epoch 6/15\n",
      "1236/1236 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9527Restoring model weights from the end of the best epoch.\n",
      "1236/1236 [==============================] - 97s 78ms/step - loss: 0.1456 - accuracy: 0.9527 - val_loss: 1.0853 - val_accuracy: 0.7417\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((x_train.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(x_train, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "    \n",
    "    clf = CNNtext(max_length,\n",
    "              encoder.classes_.__len__(),\n",
    "              tokenizer=tokenizer)\n",
    "    clf.fit(x_train[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(x_train[i_val], to_categorical(y[i_val])),\n",
    "            epochs=15,\n",
    "            callbacks=[es])\n",
    "    p_val[i_val, :] = clf.predict(x_train[i_val])\n",
    "    p_tst += clf.predict(tst) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CV):  73.8810%\n",
      "Log Loss (CV):   0.7227\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 49420\n  y sizes: 39536\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4620560cacfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m hist = CNN_BOW.fit(x_train, y_train_categorical,\n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_validation_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  shuffle=True)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 49420\n  y sizes: 39536\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "hist = CNN_BOW.fit(x_train, y_train_categorical,\n",
    "                 batch_size=batch_size, epochs=num_epochs, callbacks=[es],\n",
    "                 validation_data=(x_validation,y_validation_categorical),\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_perfomance(hist,name):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(1)\n",
    "    plt.plot(hist.history['loss'], lw=2.0, color='b', label='train')\n",
    "    plt.plot(hist.history['val_loss'], lw=2.0, color='r', label='val')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Cross-Entropy Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.figure(2)\n",
    "    plt.plot(hist.history['accuracy'], lw=2.0, color='b', label='train')\n",
    "    plt.plot(hist.history['val_accuracy'], lw=2.0, color='r', label='val')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_perfomance(hist,'CNN BOW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_predict_y_validation = CNN_BOW.predict(x_validation,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_predict_y_validation= encoder.inverse_transform(bow_predict_y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(y=None,y_predict=None,classes=None,name=None):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    sns.heatmap(confusion_matrix(y,y_predict), \n",
    "                xticklabels=classes,\n",
    "                yticklabels=classes)\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_val,bow_predict_y_validation,encoder.classes_,'Validation accuracy CNN BOW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-eb91f69fdacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# submission\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'open/sample_submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msample_submission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "# submission\n",
    "sample_submission = pd.read_csv('open/sample_submission.csv', encoding = 'utf-8')\n",
    "sample_submission[['0','1','2','3','4']] = pred\n",
    "sample_submission\n",
    "\n",
    "sample_submission.to_csv('open/sub/submission_CNN_shared_cv7227.csv', index = False, encoding = 'utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
